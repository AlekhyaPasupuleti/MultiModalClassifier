{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlekhyaPasupuleti/MultiModalClassifier/blob/main/Alekhya_TFinference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b991cac1",
      "metadata": {
        "id": "b991cac1"
      },
      "outputs": [],
      "source": [
        "import configargparse #pip install configargparse\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5ebac4",
      "metadata": {
        "id": "ea5ebac4"
      },
      "outputs": [],
      "source": [
        "model = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de8c2b1",
      "metadata": {
        "id": "3de8c2b1"
      },
      "outputs": [],
      "source": [
        "parser = configargparse.ArgParser(description='myTFClassifyInference')\n",
        "parser.add_argument('--data_name', type=str, default='fashionMNIST',\n",
        "                    help='data name: mnist, fashionMNIST, flower')\n",
        "parser.add_argument('--data_type', default='kerasdataset', choices=['tfds', 'kerasdataset', 'imagefolder', 'TFrecord'],\n",
        "                    help='the type of data')  # gs://cmpelkk_imagetest/*.tfrec\n",
        "parser.add_argument('--data_path', type=str, default='/home/lkk/.keras/datasets/flower_photos',\n",
        "                    help='path to get data')\n",
        "parser.add_argument('--img_height', type=int, default=28,\n",
        "                    help='resize to img height')\n",
        "parser.add_argument('--img_width', type=int, default=28,\n",
        "                    help='resize to img width')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c7a097",
      "metadata": {
        "id": "99c7a097"
      },
      "outputs": [],
      "source": [
        "# network\n",
        "parser.add_argument('--model_name', default='cnnsimple4', choices=['cnnsimple1', 'cnnsimple2', 'cnnsimple3', 'cnnsimple4','mobilenetmodel1'],\n",
        "                    help='the network')\n",
        "parser.add_argument('--model_path', type=str, default='./outputs/flower_mobilenetmodel1_0630',\n",
        "                    help='Model path.')\n",
        "parser.add_argument('--GPU', type=bool, default=True,\n",
        "                    help='use GPU')\n",
        "parser.add_argument('--TPU', type=bool, default=False,\n",
        "                    help='use GPU')\n",
        "parser.add_argument('--MIXED_PRECISION', type=bool, default=False,\n",
        "                    help='use MIXED_PRECISION')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dab7912",
      "metadata": {
        "id": "9dab7912"
      },
      "outputs": [],
      "source": [
        "args = parser.parse_args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a5f2c5",
      "metadata": {
        "id": "93a5f2c5"
      },
      "outputs": [],
      "source": [
        "def loadsavedmodel(path):\n",
        "    reconstructed_model = tf.keras.models.load_model(path)#\"gs://cmpelkk_imagetest/saved_models/my_savedmodel202102\")\n",
        "    reconstructed_model.summary()\n",
        "    return reconstructed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d0f599",
      "metadata": {
        "id": "f0d0f599"
      },
      "outputs": [],
      "source": [
        "def tfgetimagearray(path, img_height, img_width):\n",
        "    sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
        "    sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7fb44a0",
      "metadata": {
        "id": "e7fb44a0"
      },
      "outputs": [],
      "source": [
        " img = tf.keras.preprocessing.image.load_img(\n",
        "        sunflower_path, target_size=(img_height, img_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e93cc02",
      "metadata": {
        "id": "7e93cc02"
      },
      "outputs": [],
      "source": [
        "img_array = tf.keras.preprocessing.image.img_to_array(img) #(224, 224, 3)\n",
        "    print('Data Type: %s' % img_array.dtype) #float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d81a344",
      "metadata": {
        "id": "1d81a344"
      },
      "outputs": [],
      "source": [
        "# normalize to the range 0-1\n",
        "    img_array /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af83b83b",
      "metadata": {
        "id": "af83b83b"
      },
      "outputs": [],
      "source": [
        "return img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb56f22",
      "metadata": {
        "id": "8fb56f22"
      },
      "outputs": [],
      "source": [
        "def pltgetonlineimagearray(url):\n",
        "    import matplotlib.pyplot as plt \n",
        "    from urllib.request import urlopen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab963217",
      "metadata": {
        "id": "ab963217"
      },
      "outputs": [],
      "source": [
        "img = plt.imread(urlopen(url), format='JPG')\n",
        "    plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8fc5e6",
      "metadata": {
        "id": "4c8fc5e6"
      },
      "outputs": [],
      "source": [
        "def PILgetonlineimagearray(url, img_height, img_width):\n",
        "    from PIL import Image\n",
        "    from numpy import asarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fd3d31",
      "metadata": {
        "id": "d1fd3d31"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "    from PIL import Image, ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bdab637",
      "metadata": {
        "id": "4bdab637"
      },
      "outputs": [],
      "source": [
        " image = Image.open(urlopen(url))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccaa5c79",
      "metadata": {
        "id": "ccaa5c79"
      },
      "outputs": [],
      "source": [
        "  # Size of the image in pixels (size of original image)\n",
        "    # (This is not mandatory)\n",
        "    width, height = image.size\n",
        "    image=image.resize((img_width, img_height)) #(width, height) https://pillow.readthedocs.io/en/stable/reference/Image.html\n",
        "    image=ImageOps.grayscale(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61f6ce98",
      "metadata": {
        "id": "61f6ce98"
      },
      "outputs": [],
      "source": [
        "# imgpath=requests.get(url, stream=True).raw\n",
        "    # image = Image.open(imgpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4379cf8b",
      "metadata": {
        "id": "4379cf8b"
      },
      "outputs": [],
      "source": [
        " pixels = asarray(image) #to numpy array\n",
        "    # confirm pixel range is 0-255\n",
        "    print('Data Type: %s' % pixels.dtype)\n",
        "    print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
        "    # convert from integers to floats\n",
        "    pixels = pixels.astype('float32')\n",
        "    # normalize to the range 0-1\n",
        "    pixels /= 255.0\n",
        "    # confirm the normalization\n",
        "    print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e00655",
      "metadata": {
        "id": "b8e00655"
      },
      "outputs": [],
      "source": [
        "print('Data Type: %s' % pixels.dtype) #float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4edc286",
      "metadata": {
        "id": "c4edc286"
      },
      "outputs": [],
      "source": [
        "return pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b36e69d",
      "metadata": {
        "id": "2b36e69d"
      },
      "outputs": [],
      "source": [
        "def inference(infermodel, img_np, class_names):\n",
        "    img_array = tf.expand_dims(img_np, 0) # Create a batch (1, 224, 224, 3)\n",
        "\n",
        "    predictions = infermodel.predict(img_array)#(1, 5)\n",
        "    score = tf.nn.softmax(predictions[0])#Tensor: shape=(5,)\n",
        "\n",
        "    print(\n",
        "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "        .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce306d32",
      "metadata": {
        "id": "ce306d32"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "    model=loadsavedmodel('C:/fall2022/255/bonus_final/MultiModalClassifier/TFClassifier/outputs/fashion')\n",
        "\n",
        "    url='https://cdn.shopify.com/s/files/1/1748/4357/products/merry-new-year-unisex-t-shirt.jpg?v=1667874550'#rose\n",
        "    img_array = PILgetonlineimagearray(url, args.img_height, args.img_width)\n",
        "\n",
        "    pltgetonlineimagearray(url)\n",
        "    #img_array = tfgetimagearray(args.data_path, args.img_height, args.img_width)\n",
        "\n",
        "    class_names=['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "    inference(model, img_array, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0418766",
      "metadata": {
        "id": "f0418766"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}